{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study\n",
    "\n",
    "> 3.1.5 장에 해당하는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "# 2.2.8 장에서 정의한 훈련 및 테스트 함수를 불러온다.\n",
    "from train_utils import train, test, main\n",
    "\n",
    "# 데이터 셋 불러오기\n",
    "train_dataset = datasets.CIFAR10('./data', train=True, download=True, \n",
    "                                 transform=transforms.ToTensor())\n",
    "test_dataset = datasets.CIFAR10('./data', train=False, \n",
    "                                transform=transforms.ToTensor())\n",
    "\n",
    "# 환경 변수 설정\n",
    "BATCH = 128  # 미니배치크기\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'  # 디바이스\n",
    "STEP = 30  # 총 반복스텝\n",
    "PRINT_STEP = 180  # 경과 print 기간\n",
    "\n",
    "# 데이터로더 선언\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 3-13\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, n_in=32, output_size=10):\n",
    "        super(AlexNet, self).__init__()\n",
    "        \"\"\"\n",
    "        config:\n",
    "        - kernel: c_out, k, s, p\n",
    "        - pool: maxpool, (kernel_size=3, stride=2, padding=0)\n",
    "        \"\"\"\n",
    "        self.n_in = n_in\n",
    "        config = [(96, 11, 4, 0), \"M\", (256, 5, 1, 2), \"M\", \n",
    "                  (384, 3, 1, 1), (384, 3, 1, 1), (256, 3, 1, 1), \"M\"]\n",
    "        \n",
    "        self.convs = self._make_layers(config)\n",
    "        self.fc = nn.Sequential(\n",
    "                    nn.Linear(self._get_fc_input(config), 4096),\n",
    "                    nn.Linear(4096, 4096),\n",
    "                    nn.Linear(4096, output_size),\n",
    "                    )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.convs(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, config):\n",
    "        layers = []\n",
    "        ch_in = 3\n",
    "        for x in config:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=3, stride=2)]\n",
    "            else:\n",
    "                ch_out, k, s, p = x\n",
    "                layers += [nn.Conv2d(ch_in, ch_out, \n",
    "                                     kernel_size=k, stride=s, padding=p),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                ch_in = ch_out\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def _get_fc_input(self, config):\n",
    "        n_in = self.n_in\n",
    "        for x in config:\n",
    "            if x == \"M\":\n",
    "                pool_k, pool_s = 3, 2\n",
    "                pool_n_out = (n_in - pool_k)/pool_s + 1\n",
    "                n_in = pool_n_out\n",
    "            else:\n",
    "                ch_out, k, s, p = x\n",
    "            \n",
    "                conv_n_out = (n_in + 2*p - k)/s + 1\n",
    "                n_in = conv_n_out\n",
    "            \n",
    "        fc_input = int(ch_out*n_in*n_in)\n",
    "        return fc_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 3-14\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, vgg_name, n_in=32, output_size=10):\n",
    "        super(VGG, self).__init__()\n",
    "        \"\"\"reference: https://github.com/kuangliu/pytorch-cifar\"\"\"\n",
    "        self.n_in = n_in\n",
    "        config = {\n",
    "            'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "            'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "            'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "            'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "        }\n",
    "        \n",
    "        self.convs = self._make_layers(config[vgg_name])\n",
    "        self.fc = nn.Linear(self._get_fc_input(config[vgg_name]), output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.convs(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, config):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in config:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def _get_fc_input(self, config):\n",
    "        n_in = self.n_in\n",
    "        for x in config:\n",
    "            if x == \"M\":\n",
    "                pool_k, pool_s = 2, 2\n",
    "                pool_n_out = (n_in - pool_k)/pool_s + 1\n",
    "                n_in = pool_n_out\n",
    "            else:\n",
    "                ch_out = x\n",
    "                k, s, p = 3, 1, 1\n",
    "                conv_n_out = (n_in + 2*p - k)/s + 1\n",
    "                n_in = conv_n_out\n",
    "            \n",
    "        fc_input = int(ch_out*n_in*n_in)\n",
    "        return fc_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Step: 1 (00.00%)  \tLoss: 2.5153\n",
      "Train Step: 1 (46.08%)  \tLoss: 1.3035\n",
      "Train Step: 1 (92.16%)  \tLoss: 1.0016\n",
      "Test set: Average loss: 1.4983, Accuracy: 5158/10000 (51.58%)\n",
      "\n",
      "Train Step: 2 (00.00%)  \tLoss: 0.9769\n",
      "Train Step: 2 (46.08%)  \tLoss: 1.0267\n",
      "Train Step: 2 (92.16%)  \tLoss: 0.9284\n",
      "Test set: Average loss: 0.9764, Accuracy: 6552/10000 (65.52%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 3 (00.00%)  \tLoss: 0.7892\n",
      "Train Step: 3 (46.08%)  \tLoss: 0.7350\n",
      "Train Step: 3 (92.16%)  \tLoss: 0.6416\n",
      "Test set: Average loss: 0.6630, Accuracy: 7779/10000 (77.79%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 4 (00.00%)  \tLoss: 0.5832\n",
      "Train Step: 4 (46.08%)  \tLoss: 0.4396\n",
      "Train Step: 4 (92.16%)  \tLoss: 0.5759\n",
      "Test set: Average loss: 0.7363, Accuracy: 7535/10000 (75.35%)\n",
      "\n",
      "Train Step: 5 (00.00%)  \tLoss: 0.3670\n",
      "Train Step: 5 (46.08%)  \tLoss: 0.4801\n",
      "Train Step: 5 (92.16%)  \tLoss: 0.3762\n",
      "Test set: Average loss: 0.5723, Accuracy: 8091/10000 (80.91%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 6 (00.00%)  \tLoss: 0.3123\n",
      "Train Step: 6 (46.08%)  \tLoss: 0.1957\n",
      "Train Step: 6 (92.16%)  \tLoss: 0.3395\n",
      "Test set: Average loss: 0.5533, Accuracy: 8229/10000 (82.29%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 7 (00.00%)  \tLoss: 0.2147\n",
      "Train Step: 7 (46.08%)  \tLoss: 0.2240\n",
      "Train Step: 7 (92.16%)  \tLoss: 0.2740\n",
      "Test set: Average loss: 0.5502, Accuracy: 8280/10000 (82.80%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 8 (00.00%)  \tLoss: 0.1452\n",
      "Train Step: 8 (46.08%)  \tLoss: 0.2197\n",
      "Train Step: 8 (92.16%)  \tLoss: 0.1865\n",
      "Test set: Average loss: 0.6055, Accuracy: 8211/10000 (82.11%)\n",
      "\n",
      "Train Step: 9 (00.00%)  \tLoss: 0.0950\n",
      "Train Step: 9 (46.08%)  \tLoss: 0.2444\n",
      "Train Step: 9 (92.16%)  \tLoss: 0.1120\n",
      "Test set: Average loss: 0.5537, Accuracy: 8336/10000 (83.36%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 10 (00.00%)  \tLoss: 0.1103\n",
      "Train Step: 10 (46.08%)  \tLoss: 0.1513\n",
      "Train Step: 10 (92.16%)  \tLoss: 0.1653\n",
      "Test set: Average loss: 0.6207, Accuracy: 8325/10000 (83.25%)\n",
      "\n",
      "Train Step: 11 (00.00%)  \tLoss: 0.0893\n",
      "Train Step: 11 (46.08%)  \tLoss: 0.1148\n",
      "Train Step: 11 (92.16%)  \tLoss: 0.1600\n",
      "Test set: Average loss: 0.8363, Accuracy: 7901/10000 (79.01%)\n",
      "\n",
      "Train Step: 12 (00.00%)  \tLoss: 0.1283\n",
      "Train Step: 12 (46.08%)  \tLoss: 0.0790\n",
      "Train Step: 12 (92.16%)  \tLoss: 0.1089\n",
      "Test set: Average loss: 0.6815, Accuracy: 8335/10000 (83.35%)\n",
      "\n",
      "Train Step: 13 (00.00%)  \tLoss: 0.0647\n",
      "Train Step: 13 (46.08%)  \tLoss: 0.1259\n",
      "Train Step: 13 (92.16%)  \tLoss: 0.1680\n",
      "Test set: Average loss: 0.5942, Accuracy: 8496/10000 (84.96%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 14 (00.00%)  \tLoss: 0.0486\n",
      "Train Step: 14 (46.08%)  \tLoss: 0.1077\n",
      "Train Step: 14 (92.16%)  \tLoss: 0.0538\n",
      "Test set: Average loss: 0.7495, Accuracy: 8253/10000 (82.53%)\n",
      "\n",
      "Train Step: 15 (00.00%)  \tLoss: 0.0352\n",
      "Train Step: 15 (46.08%)  \tLoss: 0.0736\n",
      "Train Step: 15 (92.16%)  \tLoss: 0.0193\n",
      "Test set: Average loss: 0.8452, Accuracy: 8062/10000 (80.62%)\n",
      "\n",
      "Train Step: 16 (00.00%)  \tLoss: 0.1102\n",
      "Train Step: 16 (46.08%)  \tLoss: 0.0534\n",
      "Train Step: 16 (92.16%)  \tLoss: 0.0510\n",
      "Test set: Average loss: 0.7140, Accuracy: 8413/10000 (84.13%)\n",
      "\n",
      "Train Step: 17 (00.00%)  \tLoss: 0.0304\n",
      "Train Step: 17 (46.08%)  \tLoss: 0.0234\n",
      "Train Step: 17 (92.16%)  \tLoss: 0.0566\n",
      "Test set: Average loss: 0.6422, Accuracy: 8527/10000 (85.27%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 18 (00.00%)  \tLoss: 0.0463\n",
      "Train Step: 18 (46.08%)  \tLoss: 0.0219\n",
      "Train Step: 18 (92.16%)  \tLoss: 0.0661\n",
      "Test set: Average loss: 0.6509, Accuracy: 8514/10000 (85.14%)\n",
      "\n",
      "Train Step: 19 (00.00%)  \tLoss: 0.0824\n",
      "Train Step: 19 (46.08%)  \tLoss: 0.0694\n",
      "Train Step: 19 (92.16%)  \tLoss: 0.0174\n",
      "Test set: Average loss: 0.6303, Accuracy: 8584/10000 (85.84%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 20 (00.00%)  \tLoss: 0.0557\n",
      "Train Step: 20 (46.08%)  \tLoss: 0.0611\n",
      "Train Step: 20 (92.16%)  \tLoss: 0.0502\n",
      "Test set: Average loss: 0.6414, Accuracy: 8566/10000 (85.66%)\n",
      "\n",
      "Train Step: 21 (00.00%)  \tLoss: 0.0199\n",
      "Train Step: 21 (46.08%)  \tLoss: 0.0381\n",
      "Train Step: 21 (92.16%)  \tLoss: 0.0335\n",
      "Test set: Average loss: 0.6698, Accuracy: 8577/10000 (85.77%)\n",
      "\n",
      "Train Step: 22 (00.00%)  \tLoss: 0.0228\n",
      "Train Step: 22 (46.08%)  \tLoss: 0.0235\n",
      "Train Step: 22 (92.16%)  \tLoss: 0.0481\n",
      "Test set: Average loss: 0.7593, Accuracy: 8506/10000 (85.06%)\n",
      "\n",
      "Train Step: 23 (00.00%)  \tLoss: 0.0137\n",
      "Train Step: 23 (46.08%)  \tLoss: 0.0203\n",
      "Train Step: 23 (92.16%)  \tLoss: 0.0245\n",
      "Test set: Average loss: 0.7341, Accuracy: 8438/10000 (84.38%)\n",
      "\n",
      "Train Step: 24 (00.00%)  \tLoss: 0.0501\n",
      "Train Step: 24 (46.08%)  \tLoss: 0.0256\n",
      "Train Step: 24 (92.16%)  \tLoss: 0.0124\n",
      "Test set: Average loss: 0.7287, Accuracy: 8487/10000 (84.87%)\n",
      "\n",
      "Train Step: 25 (00.00%)  \tLoss: 0.0088\n",
      "Train Step: 25 (46.08%)  \tLoss: 0.0387\n",
      "Train Step: 25 (92.16%)  \tLoss: 0.0506\n",
      "Test set: Average loss: 0.7943, Accuracy: 8350/10000 (83.50%)\n",
      "\n",
      "Train Step: 26 (00.00%)  \tLoss: 0.0046\n",
      "Train Step: 26 (46.08%)  \tLoss: 0.0502\n",
      "Train Step: 26 (92.16%)  \tLoss: 0.1142\n",
      "Test set: Average loss: 0.8147, Accuracy: 8433/10000 (84.33%)\n",
      "\n",
      "Train Step: 27 (00.00%)  \tLoss: 0.0834\n",
      "Train Step: 27 (46.08%)  \tLoss: 0.0234\n",
      "Train Step: 27 (92.16%)  \tLoss: 0.0607\n",
      "Test set: Average loss: 0.7417, Accuracy: 8520/10000 (85.20%)\n",
      "\n",
      "Train Step: 28 (00.00%)  \tLoss: 0.0404\n",
      "Train Step: 28 (46.08%)  \tLoss: 0.0182\n",
      "Train Step: 28 (92.16%)  \tLoss: 0.0665\n",
      "Test set: Average loss: 0.6436, Accuracy: 8585/10000 (85.85%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 29 (00.00%)  \tLoss: 0.0109\n",
      "Train Step: 29 (46.08%)  \tLoss: 0.0285\n",
      "Train Step: 29 (92.16%)  \tLoss: 0.0450\n",
      "Test set: Average loss: 0.6975, Accuracy: 8566/10000 (85.66%)\n",
      "\n",
      "Train Step: 30 (00.00%)  \tLoss: 0.0245\n",
      "Train Step: 30 (46.08%)  \tLoss: 0.0491\n",
      "Train Step: 30 (92.16%)  \tLoss: 0.0080\n",
      "Test set: Average loss: 0.7336, Accuracy: 8581/10000 (85.81%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 모델 선언\n",
    "torch.manual_seed(70)\n",
    "model = VGG(vgg_name=\"VGG16\", n_in=32, output_size=10).to(DEVICE)\n",
    "# 손실함수 선언\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "# 옵티마이저 선언\n",
    "optimizer = optim.Adam(model.parameters()) \n",
    "\n",
    "main(model=model, \n",
    "     train_loader=train_loader, \n",
    "     test_loader=test_loader, \n",
    "     loss_func=loss_function, \n",
    "     optimizer=optimizer, \n",
    "     n_step=STEP,\n",
    "     device=DEVICE,\n",
    "     save_path=\"cifar10_vgg16.pt\", \n",
    "     print_step=PRINT_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
