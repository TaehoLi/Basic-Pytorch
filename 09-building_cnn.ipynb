{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 합성곱 네트워크 만들기\n",
    "\n",
    "> 3.1.4 장에 해당하는 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 패키지 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "# 2.2.8 장에서 정의한 훈련 및 테스트 함수를 불러온다.\n",
    "from train_utils import train, test, main\n",
    "# 시각화를 위한 matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 살펴보기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Number of Traing Set 50000, Test Set 10000\n",
      "\n",
      "Target: car\n",
      "Size of Image: torch.Size([3, 32, 32])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 코드 3-9\n",
    "\n",
    "torch.manual_seed(70)\n",
    "# 데이터 셋 불러오기\n",
    "train_dataset = datasets.CIFAR10('./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_dataset = datasets.CIFAR10('./data', train=False, transform=transforms.ToTensor())\n",
    "# 데이터 개수 알아보기\n",
    "print(\"Number of Traing Set {}, Test Set {}\\n\".format(len(train_dataset), len(test_dataset)))\n",
    "\n",
    "# Cifar 10 데이터는 총 10개 카테고리가 포함된 사물이미지가 있다\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', \n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# 랜덤 이미지 살펴보기 \n",
    "idx = torch.randint(0, len(train_dataset), (1,)).item()\n",
    "random_image = train_dataset[idx][0]\n",
    "target_num = train_dataset[idx][1]\n",
    "\n",
    "# 해당하는 사물 카테고리 및 이미지 크기 살펴보기\n",
    "print(\"Target: {}\".format(classes[target_num]))\n",
    "print(\"Size of Image: {}\".format(random_image.size()))\n",
    "# plt.imshow 는 (높이, 넓이, 채널) 형태로 입력을 받아야 출력 가능하다.\n",
    "plt.imshow(random_image.numpy().transpose(1, 2, 0))  \n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경 변수 설정\n",
    "BATCH = 128  # 미니배치크기\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'  # 디바이스\n",
    "STEP = 30  # 총 반복스텝\n",
    "PRINT_STEP = 180  # 경과 print 기간\n",
    "\n",
    "# 데이터로더 선언\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 합성곱 신경망 네트워크 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 3-10\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.flatten = lambda x: x.view(x.size(0), -1)\n",
    "        # Convolution Operation Layer\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=5, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=2, stride=1, padding=0)\n",
    "        # Activation Layer\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        # MaxPool Layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # Fully Connect Layer\n",
    "        self.fc = nn.Linear(784, 10)\n",
    "        \n",
    "    def forward(self, x): \n",
    "        ## Convolutional Layer\n",
    "        # input: (batch, 3, 32, 32) \n",
    "        # > conv1: (batch, 8, 30, 30) \n",
    "        # > pool1: (batch, 8, 15, 15)\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # > conv2: (batch, 16, 14, 14) \n",
    "        # > pool2: (batch, 16, 7, 7)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        ## Fully Connect Layer\n",
    "        # flatten\n",
    "        x = self.flatten(x)\n",
    "        # input: (batch, 32*6*6) > output: (batch, 10)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 선언\n",
    "torch.manual_seed(70)\n",
    "model = CNN().to(DEVICE)\n",
    "# 손실함수 선언\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "# 옵티마이저 선언\n",
    "optimizer = optim.Adam(model.parameters()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 및 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Step: 1 (00.00%)  \tLoss: 2.3060\n",
      "Train Step: 1 (46.08%)  \tLoss: 1.7408\n",
      "Train Step: 1 (92.16%)  \tLoss: 1.5804\n",
      "Test set: Average loss: 1.5813, Accuracy: 4380/10000 (43.80%)\n",
      "\n",
      "Train Step: 2 (00.00%)  \tLoss: 1.5674\n",
      "Train Step: 2 (46.08%)  \tLoss: 1.5562\n",
      "Train Step: 2 (92.16%)  \tLoss: 1.4554\n",
      "Test set: Average loss: 1.4661, Accuracy: 4866/10000 (48.66%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 3 (00.00%)  \tLoss: 1.4137\n",
      "Train Step: 3 (46.08%)  \tLoss: 1.3320\n",
      "Train Step: 3 (92.16%)  \tLoss: 1.4532\n",
      "Test set: Average loss: 1.4189, Accuracy: 4950/10000 (49.50%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 4 (00.00%)  \tLoss: 1.2500\n",
      "Train Step: 4 (46.08%)  \tLoss: 1.4422\n",
      "Train Step: 4 (92.16%)  \tLoss: 1.3553\n",
      "Test set: Average loss: 1.3541, Accuracy: 5191/10000 (51.91%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 5 (00.00%)  \tLoss: 1.4818\n",
      "Train Step: 5 (46.08%)  \tLoss: 1.2701\n",
      "Train Step: 5 (92.16%)  \tLoss: 1.3148\n",
      "Test set: Average loss: 1.3448, Accuracy: 5256/10000 (52.56%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 6 (00.00%)  \tLoss: 1.4322\n",
      "Train Step: 6 (46.08%)  \tLoss: 1.3666\n",
      "Train Step: 6 (92.16%)  \tLoss: 1.1529\n",
      "Test set: Average loss: 1.3077, Accuracy: 5409/10000 (54.09%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 7 (00.00%)  \tLoss: 1.2575\n",
      "Train Step: 7 (46.08%)  \tLoss: 1.3398\n",
      "Train Step: 7 (92.16%)  \tLoss: 1.1708\n",
      "Test set: Average loss: 1.2828, Accuracy: 5462/10000 (54.62%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 8 (00.00%)  \tLoss: 1.2210\n",
      "Train Step: 8 (46.08%)  \tLoss: 1.2622\n",
      "Train Step: 8 (92.16%)  \tLoss: 1.2298\n",
      "Test set: Average loss: 1.2686, Accuracy: 5510/10000 (55.10%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 9 (00.00%)  \tLoss: 1.1850\n",
      "Train Step: 9 (46.08%)  \tLoss: 1.2256\n",
      "Train Step: 9 (92.16%)  \tLoss: 1.2158\n",
      "Test set: Average loss: 1.2323, Accuracy: 5695/10000 (56.95%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 10 (00.00%)  \tLoss: 1.2676\n",
      "Train Step: 10 (46.08%)  \tLoss: 1.1505\n",
      "Train Step: 10 (92.16%)  \tLoss: 1.1558\n",
      "Test set: Average loss: 1.2485, Accuracy: 5622/10000 (56.22%)\n",
      "\n",
      "Train Step: 11 (00.00%)  \tLoss: 1.2855\n",
      "Train Step: 11 (46.08%)  \tLoss: 0.9742\n",
      "Train Step: 11 (92.16%)  \tLoss: 1.3066\n",
      "Test set: Average loss: 1.2022, Accuracy: 5817/10000 (58.17%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 12 (00.00%)  \tLoss: 1.1397\n",
      "Train Step: 12 (46.08%)  \tLoss: 1.2305\n",
      "Train Step: 12 (92.16%)  \tLoss: 1.0119\n",
      "Test set: Average loss: 1.2234, Accuracy: 5752/10000 (57.52%)\n",
      "\n",
      "Train Step: 13 (00.00%)  \tLoss: 1.1727\n",
      "Train Step: 13 (46.08%)  \tLoss: 1.0881\n",
      "Train Step: 13 (92.16%)  \tLoss: 1.4368\n",
      "Test set: Average loss: 1.2080, Accuracy: 5800/10000 (58.00%)\n",
      "\n",
      "Train Step: 14 (00.00%)  \tLoss: 1.0172\n",
      "Train Step: 14 (46.08%)  \tLoss: 1.1331\n",
      "Train Step: 14 (92.16%)  \tLoss: 1.2310\n",
      "Test set: Average loss: 1.2219, Accuracy: 5746/10000 (57.46%)\n",
      "\n",
      "Train Step: 15 (00.00%)  \tLoss: 1.1640\n",
      "Train Step: 15 (46.08%)  \tLoss: 1.0900\n",
      "Train Step: 15 (92.16%)  \tLoss: 1.1833\n",
      "Test set: Average loss: 1.1758, Accuracy: 5920/10000 (59.20%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 16 (00.00%)  \tLoss: 1.2028\n",
      "Train Step: 16 (46.08%)  \tLoss: 1.0832\n",
      "Train Step: 16 (92.16%)  \tLoss: 1.1271\n",
      "Test set: Average loss: 1.1750, Accuracy: 5880/10000 (58.80%)\n",
      "\n",
      "Train Step: 17 (00.00%)  \tLoss: 1.0484\n",
      "Train Step: 17 (46.08%)  \tLoss: 1.2788\n",
      "Train Step: 17 (92.16%)  \tLoss: 1.1188\n",
      "Test set: Average loss: 1.1577, Accuracy: 5951/10000 (59.51%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 18 (00.00%)  \tLoss: 1.0297\n",
      "Train Step: 18 (46.08%)  \tLoss: 1.0994\n",
      "Train Step: 18 (92.16%)  \tLoss: 1.1460\n",
      "Test set: Average loss: 1.1711, Accuracy: 5934/10000 (59.34%)\n",
      "\n",
      "Train Step: 19 (00.00%)  \tLoss: 1.1971\n",
      "Train Step: 19 (46.08%)  \tLoss: 1.1226\n",
      "Train Step: 19 (92.16%)  \tLoss: 1.1028\n",
      "Test set: Average loss: 1.1460, Accuracy: 6008/10000 (60.08%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 20 (00.00%)  \tLoss: 1.0178\n",
      "Train Step: 20 (46.08%)  \tLoss: 1.0841\n",
      "Train Step: 20 (92.16%)  \tLoss: 1.1124\n",
      "Test set: Average loss: 1.1353, Accuracy: 6033/10000 (60.33%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 21 (00.00%)  \tLoss: 1.2613\n",
      "Train Step: 21 (46.08%)  \tLoss: 1.2300\n",
      "Train Step: 21 (92.16%)  \tLoss: 0.9684\n",
      "Test set: Average loss: 1.1438, Accuracy: 6032/10000 (60.32%)\n",
      "\n",
      "Train Step: 22 (00.00%)  \tLoss: 0.9113\n",
      "Train Step: 22 (46.08%)  \tLoss: 1.1005\n",
      "Train Step: 22 (92.16%)  \tLoss: 0.9748\n",
      "Test set: Average loss: 1.1315, Accuracy: 6010/10000 (60.10%)\n",
      "\n",
      "Train Step: 23 (00.00%)  \tLoss: 1.0607\n",
      "Train Step: 23 (46.08%)  \tLoss: 1.1897\n",
      "Train Step: 23 (92.16%)  \tLoss: 1.1229\n",
      "Test set: Average loss: 1.1341, Accuracy: 6088/10000 (60.88%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 24 (00.00%)  \tLoss: 0.9548\n",
      "Train Step: 24 (46.08%)  \tLoss: 1.1264\n",
      "Train Step: 24 (92.16%)  \tLoss: 1.0459\n",
      "Test set: Average loss: 1.1260, Accuracy: 6092/10000 (60.92%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 25 (00.00%)  \tLoss: 1.0892\n",
      "Train Step: 25 (46.08%)  \tLoss: 1.0065\n",
      "Train Step: 25 (92.16%)  \tLoss: 0.8817\n",
      "Test set: Average loss: 1.1237, Accuracy: 6066/10000 (60.66%)\n",
      "\n",
      "Train Step: 26 (00.00%)  \tLoss: 1.1161\n",
      "Train Step: 26 (46.08%)  \tLoss: 1.0110\n",
      "Train Step: 26 (92.16%)  \tLoss: 1.1834\n",
      "Test set: Average loss: 1.1251, Accuracy: 6095/10000 (60.95%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 27 (00.00%)  \tLoss: 0.8699\n",
      "Train Step: 27 (46.08%)  \tLoss: 0.9874\n",
      "Train Step: 27 (92.16%)  \tLoss: 0.8738\n",
      "Test set: Average loss: 1.1184, Accuracy: 6090/10000 (60.90%)\n",
      "\n",
      "Train Step: 28 (00.00%)  \tLoss: 1.3218\n",
      "Train Step: 28 (46.08%)  \tLoss: 1.0016\n",
      "Train Step: 28 (92.16%)  \tLoss: 1.1049\n",
      "Test set: Average loss: 1.0993, Accuracy: 6163/10000 (61.63%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 29 (00.00%)  \tLoss: 1.0990\n",
      "Train Step: 29 (46.08%)  \tLoss: 1.0083\n",
      "Train Step: 29 (92.16%)  \tLoss: 0.9977\n",
      "Test set: Average loss: 1.1106, Accuracy: 6136/10000 (61.36%)\n",
      "\n",
      "Train Step: 30 (00.00%)  \tLoss: 0.9873\n",
      "Train Step: 30 (46.08%)  \tLoss: 0.9833\n",
      "Train Step: 30 (92.16%)  \tLoss: 1.1421\n",
      "Test set: Average loss: 1.1015, Accuracy: 6189/10000 (61.89%)\n",
      "discard previous state, best model state saved!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 코드 3-11\n",
    "\n",
    "main(model=model, \n",
    "     train_loader=train_loader, \n",
    "     test_loader=test_loader, \n",
    "     loss_func=loss_function, \n",
    "     optimizer=optimizer, \n",
    "     n_step=STEP,\n",
    "     device=DEVICE,\n",
    "     save_path=\"cifar10_model.pt\", \n",
    "     print_step=PRINT_STEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 더 큰 CNN 모델로 학습 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Train Step: 1 (00.00%)  \tLoss: 2.3042\n",
      "Train Step: 1 (46.08%)  \tLoss: 1.3712\n",
      "Train Step: 1 (92.16%)  \tLoss: 1.0144\n",
      "Test set: Average loss: 1.7997, Accuracy: 3780/10000 (37.80%)\n",
      "\n",
      "Train Step: 2 (00.00%)  \tLoss: 1.3052\n",
      "Train Step: 2 (46.08%)  \tLoss: 0.8439\n",
      "Train Step: 2 (92.16%)  \tLoss: 0.9297\n",
      "Test set: Average loss: 1.3432, Accuracy: 5236/10000 (52.36%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 3 (00.00%)  \tLoss: 1.0056\n",
      "Train Step: 3 (46.08%)  \tLoss: 0.7959\n",
      "Train Step: 3 (92.16%)  \tLoss: 0.8460\n",
      "Test set: Average loss: 0.8912, Accuracy: 6853/10000 (68.53%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 4 (00.00%)  \tLoss: 0.8769\n",
      "Train Step: 4 (46.08%)  \tLoss: 0.6495\n",
      "Train Step: 4 (92.16%)  \tLoss: 0.6807\n",
      "Test set: Average loss: 0.9761, Accuracy: 6605/10000 (66.05%)\n",
      "\n",
      "Train Step: 5 (00.00%)  \tLoss: 0.7416\n",
      "Train Step: 5 (46.08%)  \tLoss: 0.6702\n",
      "Train Step: 5 (92.16%)  \tLoss: 0.7468\n",
      "Test set: Average loss: 0.9114, Accuracy: 6857/10000 (68.57%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 6 (00.00%)  \tLoss: 0.6086\n",
      "Train Step: 6 (46.08%)  \tLoss: 0.6811\n",
      "Train Step: 6 (92.16%)  \tLoss: 0.5850\n",
      "Test set: Average loss: 1.1905, Accuracy: 6393/10000 (63.93%)\n",
      "\n",
      "Train Step: 7 (00.00%)  \tLoss: 0.6504\n",
      "Train Step: 7 (46.08%)  \tLoss: 0.5616\n",
      "Train Step: 7 (92.16%)  \tLoss: 0.4697\n",
      "Test set: Average loss: 0.9366, Accuracy: 7004/10000 (70.04%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 8 (00.00%)  \tLoss: 0.3802\n",
      "Train Step: 8 (46.08%)  \tLoss: 0.3879\n",
      "Train Step: 8 (92.16%)  \tLoss: 0.4247\n",
      "Test set: Average loss: 0.9417, Accuracy: 7021/10000 (70.21%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 9 (00.00%)  \tLoss: 0.3933\n",
      "Train Step: 9 (46.08%)  \tLoss: 0.3617\n",
      "Train Step: 9 (92.16%)  \tLoss: 0.4898\n",
      "Test set: Average loss: 0.9530, Accuracy: 7122/10000 (71.22%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 10 (00.00%)  \tLoss: 0.3361\n",
      "Train Step: 10 (46.08%)  \tLoss: 0.3306\n",
      "Train Step: 10 (92.16%)  \tLoss: 0.4401\n",
      "Test set: Average loss: 0.9641, Accuracy: 7055/10000 (70.55%)\n",
      "\n",
      "Train Step: 11 (00.00%)  \tLoss: 0.3301\n",
      "Train Step: 11 (46.08%)  \tLoss: 0.3827\n",
      "Train Step: 11 (92.16%)  \tLoss: 0.4565\n",
      "Test set: Average loss: 1.0448, Accuracy: 7137/10000 (71.37%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 12 (00.00%)  \tLoss: 0.2330\n",
      "Train Step: 12 (46.08%)  \tLoss: 0.2136\n",
      "Train Step: 12 (92.16%)  \tLoss: 0.3399\n",
      "Test set: Average loss: 0.9899, Accuracy: 7218/10000 (72.18%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 13 (00.00%)  \tLoss: 0.1884\n",
      "Train Step: 13 (46.08%)  \tLoss: 0.2650\n",
      "Train Step: 13 (92.16%)  \tLoss: 0.2513\n",
      "Test set: Average loss: 0.9841, Accuracy: 7295/10000 (72.95%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 14 (00.00%)  \tLoss: 0.1898\n",
      "Train Step: 14 (46.08%)  \tLoss: 0.2546\n",
      "Train Step: 14 (92.16%)  \tLoss: 0.2164\n",
      "Test set: Average loss: 1.0280, Accuracy: 7339/10000 (73.39%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 15 (00.00%)  \tLoss: 0.1790\n",
      "Train Step: 15 (46.08%)  \tLoss: 0.1718\n",
      "Train Step: 15 (92.16%)  \tLoss: 0.1203\n",
      "Test set: Average loss: 1.2770, Accuracy: 7074/10000 (70.74%)\n",
      "\n",
      "Train Step: 16 (00.00%)  \tLoss: 0.1579\n",
      "Train Step: 16 (46.08%)  \tLoss: 0.2200\n",
      "Train Step: 16 (92.16%)  \tLoss: 0.1480\n",
      "Test set: Average loss: 1.2325, Accuracy: 7102/10000 (71.02%)\n",
      "\n",
      "Train Step: 17 (00.00%)  \tLoss: 0.1430\n",
      "Train Step: 17 (46.08%)  \tLoss: 0.1596\n",
      "Train Step: 17 (92.16%)  \tLoss: 0.1266\n",
      "Test set: Average loss: 1.2657, Accuracy: 7267/10000 (72.67%)\n",
      "\n",
      "Train Step: 18 (00.00%)  \tLoss: 0.0745\n",
      "Train Step: 18 (46.08%)  \tLoss: 0.1298\n",
      "Train Step: 18 (92.16%)  \tLoss: 0.2088\n",
      "Test set: Average loss: 1.1752, Accuracy: 7373/10000 (73.73%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 19 (00.00%)  \tLoss: 0.1595\n",
      "Train Step: 19 (46.08%)  \tLoss: 0.1059\n",
      "Train Step: 19 (92.16%)  \tLoss: 0.1363\n",
      "Test set: Average loss: 1.3421, Accuracy: 7273/10000 (72.73%)\n",
      "\n",
      "Train Step: 20 (00.00%)  \tLoss: 0.1079\n",
      "Train Step: 20 (46.08%)  \tLoss: 0.0699\n",
      "Train Step: 20 (92.16%)  \tLoss: 0.1245\n",
      "Test set: Average loss: 1.4899, Accuracy: 7126/10000 (71.26%)\n",
      "\n",
      "Train Step: 21 (00.00%)  \tLoss: 0.0996\n",
      "Train Step: 21 (46.08%)  \tLoss: 0.0788\n",
      "Train Step: 21 (92.16%)  \tLoss: 0.1381\n",
      "Test set: Average loss: 1.5098, Accuracy: 7172/10000 (71.72%)\n",
      "\n",
      "Train Step: 22 (00.00%)  \tLoss: 0.1085\n",
      "Train Step: 22 (46.08%)  \tLoss: 0.0944\n",
      "Train Step: 22 (92.16%)  \tLoss: 0.1997\n",
      "Test set: Average loss: 1.4876, Accuracy: 7094/10000 (70.94%)\n",
      "\n",
      "Train Step: 23 (00.00%)  \tLoss: 0.1076\n",
      "Train Step: 23 (46.08%)  \tLoss: 0.0358\n",
      "Train Step: 23 (92.16%)  \tLoss: 0.1242\n",
      "Test set: Average loss: 1.4235, Accuracy: 7327/10000 (73.27%)\n",
      "\n",
      "Train Step: 24 (00.00%)  \tLoss: 0.0560\n",
      "Train Step: 24 (46.08%)  \tLoss: 0.0500\n",
      "Train Step: 24 (92.16%)  \tLoss: 0.0290\n",
      "Test set: Average loss: 1.3392, Accuracy: 7455/10000 (74.55%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 25 (00.00%)  \tLoss: 0.0844\n",
      "Train Step: 25 (46.08%)  \tLoss: 0.0723\n",
      "Train Step: 25 (92.16%)  \tLoss: 0.0599\n",
      "Test set: Average loss: 1.5373, Accuracy: 7080/10000 (70.80%)\n",
      "\n",
      "Train Step: 26 (00.00%)  \tLoss: 0.0553\n",
      "Train Step: 26 (46.08%)  \tLoss: 0.0219\n",
      "Train Step: 26 (92.16%)  \tLoss: 0.0454\n",
      "Test set: Average loss: 2.3798, Accuracy: 6525/10000 (65.25%)\n",
      "\n",
      "Train Step: 27 (00.00%)  \tLoss: 0.0596\n",
      "Train Step: 27 (46.08%)  \tLoss: 0.0367\n",
      "Train Step: 27 (92.16%)  \tLoss: 0.1233\n",
      "Test set: Average loss: 1.6867, Accuracy: 7090/10000 (70.90%)\n",
      "\n",
      "Train Step: 28 (00.00%)  \tLoss: 0.0700\n",
      "Train Step: 28 (46.08%)  \tLoss: 0.0640\n",
      "Train Step: 28 (92.16%)  \tLoss: 0.0351\n",
      "Test set: Average loss: 1.4772, Accuracy: 7278/10000 (72.78%)\n",
      "\n",
      "Train Step: 29 (00.00%)  \tLoss: 0.0758\n",
      "Train Step: 29 (46.08%)  \tLoss: 0.0624\n",
      "Train Step: 29 (92.16%)  \tLoss: 0.0373\n",
      "Test set: Average loss: 1.4575, Accuracy: 7399/10000 (73.99%)\n",
      "\n",
      "Train Step: 30 (00.00%)  \tLoss: 0.0356\n",
      "Train Step: 30 (46.08%)  \tLoss: 0.0497\n",
      "Train Step: 30 (92.16%)  \tLoss: 0.0531\n",
      "Test set: Average loss: 1.6067, Accuracy: 7336/10000 (73.36%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 코드 3-12\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "# 2.2.8 장에서 정의한 훈련 및 테스트 함수를 불러온다.\n",
    "from train_utils import train, test, main\n",
    "# custom_cnn 의 CNN 모델을 불러온다.\n",
    "from custom_cnn import CNN\n",
    "\n",
    "# 데이터 셋 불러오기\n",
    "train_dataset = datasets.CIFAR10('./data', train=True, download=True, \n",
    "                                 transform=transforms.ToTensor())\n",
    "test_dataset = datasets.CIFAR10('./data', train=False, \n",
    "                                transform=transforms.ToTensor())\n",
    "\n",
    "# 환경 변수 설정\n",
    "BATCH = 128  # 미니배치크기\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'  # 디바이스\n",
    "STEP = 30  # 총 반복스텝\n",
    "PRINT_STEP = 180  # 경과 print 기간\n",
    "# 모델 환경 변수 설정\n",
    "config = [\n",
    "    ('ch_in', 3), ('n_in', 32),\n",
    "    ('conv1', (32, 7, 1, 1)), ('pool1', 2), \n",
    "    ('conv2', (64, 5, 1, 1)), ('pool2', 2), \n",
    "    ('conv3', (128, 3, 1, 0)), ('pool3', 2),\n",
    "    ('fc', (250, 50, 10))\n",
    "    ]\n",
    "\n",
    "# 데이터로더 선언\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH, shuffle=True)\n",
    "\n",
    "# 모델 선언\n",
    "torch.manual_seed(70)\n",
    "model = CNN(config).to(DEVICE)\n",
    "# 손실함수 선언\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "# 옵티마이저 선언\n",
    "optimizer = optim.Adam(model.parameters()) \n",
    "\n",
    "main(model=model, \n",
    "     train_loader=train_loader, \n",
    "     test_loader=test_loader, \n",
    "     loss_func=loss_function, \n",
    "     optimizer=optimizer, \n",
    "     n_step=STEP,\n",
    "     device=DEVICE,\n",
    "     save_path=\"cifar10_model.pt\", \n",
    "     print_step=PRINT_STEP)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 클래스 별로 정확도 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plane \t: 75.50%\n",
      "car \t: 84.10%\n",
      "bird \t: 61.30%\n",
      "cat \t: 58.20%\n",
      "deer \t: 65.90%\n",
      "dog \t: 63.60%\n",
      "frog \t: 78.00%\n",
      "horse \t: 83.70%\n",
      "ship \t: 89.20%\n",
      "truck \t: 85.40%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from custom_cnn import CNN\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', \n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# 데이터 불러오기\n",
    "test_dataset = datasets.CIFAR10('./data', train=False, \n",
    "                                transform=transforms.ToTensor())\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "BATCH = 128\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH, shuffle=True)\n",
    "\n",
    "# config\n",
    "config = [\n",
    "    ('ch_in', 3), ('n_in', 32),\n",
    "    ('conv1', (32, 7, 1, 1)), ('pool1', 2), \n",
    "    ('conv2', (64, 5, 1, 1)), ('pool2', 2), \n",
    "    ('conv3', (128, 3, 1, 0)), ('pool3', 2),\n",
    "    ('fc', (250, 50, 10))\n",
    "    ]\n",
    "\n",
    "model = CNN(config).to(DEVICE)\n",
    "# 모델 불러오기\n",
    "model_path = \"./cifar10_model.pt\"\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "# class 별로 맞춘 개수 계산하는 함수\n",
    "def cal_correct_by_class(model, test_loader, device):\n",
    "    total = torch.zeros(10)\n",
    "    correct = torch.zeros(10)\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data.to(device))\n",
    "            pred = output.cpu().softmax(1).argmax(1)\n",
    "            correct_idx = pred.masked_select((pred == target))\n",
    "            correct += torch.zeros(correct_idx.size(0), 10).scatter(1, correct_idx.view(-1, 1), 1).sum(0)\n",
    "            total += torch.zeros(target.size(0), 10).scatter(1, target.view(-1, 1), 1).sum(0)\n",
    "            \n",
    "    percentage = correct/total\n",
    "\n",
    "    return percentage\n",
    "\n",
    "percentage = cal_correct_by_class(model, test_loader, device=DEVICE)\n",
    "for cls_name, percent in zip(classes, percentage):\n",
    "    print(\"{} \\t: {:05.2f}%\".format(cls_name, percent*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
