{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-Project: 나만의 딥러닝 모델로 Mnist Dataset 학습하기\n",
    "\n",
    "> 2.2.8 장에 해당하는 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 패키기 불러오기 및 GUI 프로그램 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 2-22\n",
    "\n",
    "import os\n",
    "# matplotlib 패키지 결과물을 노트북을 실행한 브라우저 안에 보일 수 있도록 하는 명령어다. \n",
    "%matplotlib inline\n",
    "# numpy 와 pytorch 패키지 불러오기 \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# 데이터로더 및 mnist 가 내장 되어있는 torchvision 패키지에서 데이터셋 불러오기\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# 손글씨를 써볼 수 있는 GUI 프로그램\n",
    "from drawing import Drawing\n",
    "# 그림 시각화 처리를 위한 패키지\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def drawing_custom_number(preprocess, filepath=\"./figs\", return_img=True):\n",
    "    \"\"\"손글씨 입력 GUI 미니 프로그램\"\"\"\n",
    "    if (not os.path.isdir(\"figs\")) and (filepath == \"./figs\"):\n",
    "        os.mkdir(\"figs\")\n",
    "    draw = Drawing()\n",
    "    draw.main(preprocess=preprocess, filepath=filepath)\n",
    "    img = Image.open(draw.file)\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.show()\n",
    "    if return_img:\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 0\n",
      "Size of Image: (28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAHGUlEQVR4nO3dzavO+R/H8XP9jKEoC9MgRW6KpmyEmCyUhSROZKGksSEWVlMoiWxEGgtZz1hIJOSmczpZUFJ2boaFhSI1w5TUmNyl6/cPnO/7quPMnNd1zuOxnFcfrub07Fs+fa/TarfbPUCe/430BwAGJ04IJU4IJU4IJU4I9U01tlot/5QL/7J2u90a7L97ckIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUIocUKob0b6A4xG48ePL/dly5Y1br/88kt5dunSpeXearXKvd1ul/vNmzcbtxcvXpRnOzlw4EC5v3r16qv+/NHGkxNCiRNCiRNCiRNCiRNCiRNCiRNCtap7r1arVV+KjVHz5s0r9yNHjpT7li1bGrd//vmnPPv+/fty73TPOXHixHKfNGlSuX+Nhw8flvvq1asbtzdv3gz3x4nRbrcH/aF5ckIocUIocUIocUIocUIocUIoVymDmD17drnfvn273KdNm1bufX19jdvBgwfLs48fPy73Tvbu3VvuR48e/ao/v9Lpmuf48eON2/79+4f748RwlQJdRpwQSpwQSpwQSpwQSpwQSpwQakx+NeaECRPK/fDhw+U+a9asct+2bVu5nz17ttz/TZ1evbp7927jtnjx4vJsp9fR3r59W+4///xz43br1q3ybH9/f7l3I09OCCVOCCVOCCVOCCVOCCVOCCVOCDUm3+dcv359uV+5cqXcHz16VO4rVqwo905fbzmSent7G7dLly6VZ69fv17uly9fLvfq1x9euHChPLtr165yT+Z9Tugy4oRQ4oRQ4oRQ4oRQ4oRQ4oRQY/J9zk2bNpV7p+9XPXPmTLkn32N+jU7/X16/fl3uv/32W7nv27evcVuzZk15dvLkyeX+7t27ck/kyQmhxAmhxAmhxAmhxAmhxAmhxAmhRu0959q1axu3rVu3lmcvXrxY7idPnhzSZ+oGz58/b9w63d9++PDhq/7u6t3iTt8V3Om7iN1zAsNGnBBKnBBKnBBKnBBKnBBq1F6l7Ny5s3EbN25cefb3338f7o/TNaoriU5fT3no0KHh/jhjmicnhBInhBInhBInhBInhBInhBInhOraXwE4d+7ccn/8+HHj9vDhw/LsypUry/3z58/lztA8efKkcVuwYEF5dt26deXe398/pM/0X/ArAKHLiBNCiRNCiRNCiRNCiRNCiRNCde37nJs3by73b7/9tnHr9NWX7jG7z6JFi8o9+Z6ziScnhBInhBInhBInhBInhBInhBInhOrae85OWq1BX5EjWPUz6/TzfPr06XB/nBHnyQmhxAmhxAmhxAmhxAmhxAmhxAmhRu09Z/V9vGSqfmYfP34sz75//364P86I8+SEUOKEUOKEUOKEUOKEUOKEUKP2KoU8CxcuLPeZM2c2bn19feXZgYGBIX2mZJ6cEEqcEEqcEEqcEEqcEEqcEEqcEMo9J/+ZPXv2lPvkyZMbt3Pnzg33x4nnyQmhxAmhxAmhxAmhxAmhxAmhxAmhWtXXEbZardjvl/zhhx/K/dGjR43bgwcPyrNr164t91evXpU7g/vjjz/K/fvvv2/cNm7cWJ69evXqkD5Tgna7PejvN/TkhFDihFDihFDihFDihFDihFDihFBd+z7nkydPyv3atWuN24YNG8qz27dvL/djx46V+2g1Y8aMcj9//ny5T58+vdx//fXXxu3+/fvl2dHIkxNCiRNCiRNCiRNCiRNCiRNCde0rY50sX768cTt58mR5dsGCBeV++vTpcj98+HC5f/nypdxHUvW63KlTp8qzc+bMKfdnz56V+48//ti4/fXXX+XZbuaVMegy4oRQ4oRQ4oRQ4oRQ4oRQ4oRQo/aes/LTTz+V+4kTJ8p96tSp5X7jxo1y37FjR+P2559/lmc76e3tLfdFixaV++7duxu3Tq98PX/+vNxXrVpV7i9evCj30co9J3QZcUIocUIocUIocUIocUIocUKoMXnP2cmSJUvKfWBgoNynTJlS7n///Xfj9unTp/JsJ9999125Vz/vnp6enpcvXzZune5/q6+27Onp6Xn37l25j1XuOaHLiBNCiRNCiRNCiRNCiRNCiRNCueccgvnz55f76tWry33//v2N26xZs8qzT58+Lfc7d+6U+6VLl8r93r17jdubN2/KswyNe07oMuKEUOKEUOKEUOKEUOKEUOKEUO45YYS554QuI04IJU4IJU4IJU4IJU4IJU4IJU4IJU4IJU4IJU4IJU4IJU4IJU4IJU4IJU4IJU4IJU4IJU4IJU4IJU4IJU4IVX41JjByPDkhlDghlDghlDghlDghlDgh1P8B8Mhm+DAafMAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 코드 2-23\n",
    "\n",
    "torch.manual_seed(70)\n",
    "\n",
    "# 데이터셋 정의하기\n",
    "train_dataset = datasets.MNIST(root='./data',  # 데이터 경로\n",
    "                               train=True,  # 훈련데이터의 여부\n",
    "                               download=True,  # 기존에 없다면 root 경로에 다운로드를 받게 된다.\n",
    "                               transform=transforms.ToTensor())  # 텐서로 바꾸는 전처리를 한다.\n",
    "test_dataset = datasets.MNIST(root='./data', # 데이터 경로\n",
    "                              train=False,  # 훈련데이터의 여부\n",
    "                              transform=transforms.ToTensor())  # 텐서로 바꾸는 전처리를 한다.\n",
    "\n",
    "# 데이터 살펴보기: 훈련데이터 중 임의의 데이터를 골라서 보여준다\n",
    "idx = torch.randint(0, len(train_dataset), (1,)).item()\n",
    "random_image = train_dataset[idx][0].squeeze().numpy()\n",
    "target_num = train_dataset[idx][1]\n",
    "print(\"Target: {}\".format(target_num))\n",
    "print(\"Size of Image: {}\".format(random_image.shape))\n",
    "plt.imshow(random_image, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 2-24\n",
    "\n",
    "# 미니배치크기\n",
    "BATCH = 64\n",
    "# 디바이스 설정: cuda 사용할지 cpu 사용할지\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# 총 스텝 크기\n",
    "STEP = 10\n",
    "\n",
    "# 훈련 데이터로더 선언\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=BATCH, \n",
    "                          shuffle=True)\n",
    "# 테스트 데이터 로더 설정\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=BATCH, \n",
    "                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for (data, target) in train_loader:\n",
    "    print(data.size(), target.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 2-30\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.flatten = lambda x: x.view(x.size(0), -1)\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear3 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 2-25\n",
    "\n",
    "# 모델 선언\n",
    "model = Net(input_size=28*28, hidden_size=100, output_size=10).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 89610\n"
     ]
    }
   ],
   "source": [
    "# 코드 2-26\n",
    "\n",
    "# 손실함수와 옵티마이저 선언\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# 매개변수 개수 확인하기\n",
    "num_params = 0\n",
    "for params in model.parameters():\n",
    "    num_params += params.view(-1).size(0)\n",
    "print(\"Total number of parameters: {}\".format(num_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 2-27\n",
    "\n",
    "def train(model, train_loader, loss_func, optimizer, step, device, print_step=200):\n",
    "    \"\"\"train function: 1 스텝 동안 발생하는 학습과정\"\"\"\n",
    "    # 모델에게 훈련단계이라고 선언함\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # 입력과 타겟 텐서에 GPU 를 사용여부 전달\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # 경사 초기화\n",
    "        model.zero_grad()\n",
    "        # 순방향 전파\n",
    "        output = model(data)\n",
    "        # 손실값 계산\n",
    "        loss = loss_func(output, target)\n",
    "        # 역방향 전파\n",
    "        loss.backward()\n",
    "        # 매개변수 업데이트\n",
    "        optimizer.step()\n",
    "        # 중간 과정 print\n",
    "        if batch_idx % print_step == 0:\n",
    "            print('Train Step: {} ({:05.2f}%)  \\tLoss: {:.4f}'.format(\n",
    "                step, 100.*(batch_idx*train_loader.batch_size)/len(train_loader.dataset), \n",
    "                loss.item()))\n",
    "            \n",
    "def test(model, test_loader, loss_func, device):\n",
    "    \"\"\"test function\"\"\"\n",
    "    # 모델에게 평가단계이라고 선언함\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            # 입력과 타겟 텐서에 GPU 를 사용여부 전달\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # 순방향전파\n",
    "            output = model(data)\n",
    "            # 손실값 계산(합)\n",
    "            test_loss += loss_func(output, target, reduction=\"sum\").item()\n",
    "            # 예측 값에 해당하는 클래스 번호 반환\n",
    "            pred = output.softmax(1).argmax(dim=1, keepdim=True)\n",
    "            # 정확하게 예측한 개수를 기록한다\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_acc = correct / len(test_loader.dataset)\n",
    "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:05.2f}%)'.format(\n",
    "        test_loss, correct, len(test_loader.dataset), 100. * test_acc))\n",
    "    return test_loss, test_acc\n",
    "\n",
    "def main(model, train_loader, test_loader, loss_func, optimizer, n_step, device, save_path=None, print_step=200):\n",
    "    \"\"\"메인 학습 함수\"\"\"\n",
    "    test_accs = []\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for step in range(1, n_step+1):\n",
    "        # 훈련 단계\n",
    "        train(model, train_loader, loss_func, optimizer, \n",
    "              step=step, device=device, print_step=print_step)\n",
    "        # 평가 단계\n",
    "        test_loss, test_acc = test(model, test_loader, \n",
    "                                   loss_func=F.cross_entropy, \n",
    "                                   device=device)\n",
    "        # 테스트 정확도 기록\n",
    "        test_accs.append(test_acc)\n",
    "        # 모델 최적의 매개변수값을 저장할지 결정하고 기록한다.\n",
    "        if len(test_accs) >= 2:\n",
    "            if test_acc >= best_acc:\n",
    "                best_acc = test_acc\n",
    "                best_state_dict = model.state_dict()\n",
    "                print(\"discard previous state, best model state saved!\")\n",
    "        print(\"\")\n",
    "\n",
    "    # 매개변수 값 저장하기\n",
    "    if save_path is not None:\n",
    "        torch.save(best_state_dict, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Step: 1 (00.00%)  \tLoss: 2.3176\n",
      "Train Step: 1 (21.33%)  \tLoss: 0.2704\n",
      "Train Step: 1 (42.67%)  \tLoss: 0.3944\n",
      "Train Step: 1 (64.00%)  \tLoss: 0.1376\n",
      "Train Step: 1 (85.33%)  \tLoss: 0.2473\n",
      "Test set: Average loss: 0.1566, Accuracy: 9543/10000 (95.43%)\n",
      "\n",
      "Train Step: 2 (00.00%)  \tLoss: 0.2037\n",
      "Train Step: 2 (21.33%)  \tLoss: 0.1473\n",
      "Train Step: 2 (42.67%)  \tLoss: 0.1313\n",
      "Train Step: 2 (64.00%)  \tLoss: 0.1170\n",
      "Train Step: 2 (85.33%)  \tLoss: 0.0972\n",
      "Test set: Average loss: 0.1198, Accuracy: 9610/10000 (96.10%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 3 (00.00%)  \tLoss: 0.0749\n",
      "Train Step: 3 (21.33%)  \tLoss: 0.1048\n",
      "Train Step: 3 (42.67%)  \tLoss: 0.0381\n",
      "Train Step: 3 (64.00%)  \tLoss: 0.0404\n",
      "Train Step: 3 (85.33%)  \tLoss: 0.0462\n",
      "Test set: Average loss: 0.1066, Accuracy: 9662/10000 (96.62%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 4 (00.00%)  \tLoss: 0.0631\n",
      "Train Step: 4 (21.33%)  \tLoss: 0.0844\n",
      "Train Step: 4 (42.67%)  \tLoss: 0.0425\n",
      "Train Step: 4 (64.00%)  \tLoss: 0.0341\n",
      "Train Step: 4 (85.33%)  \tLoss: 0.0798\n",
      "Test set: Average loss: 0.0888, Accuracy: 9721/10000 (97.21%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 5 (00.00%)  \tLoss: 0.0155\n",
      "Train Step: 5 (21.33%)  \tLoss: 0.1525\n",
      "Train Step: 5 (42.67%)  \tLoss: 0.0196\n",
      "Train Step: 5 (64.00%)  \tLoss: 0.0421\n",
      "Train Step: 5 (85.33%)  \tLoss: 0.0361\n",
      "Test set: Average loss: 0.0906, Accuracy: 9718/10000 (97.18%)\n",
      "\n",
      "Train Step: 6 (00.00%)  \tLoss: 0.0214\n",
      "Train Step: 6 (21.33%)  \tLoss: 0.0265\n",
      "Train Step: 6 (42.67%)  \tLoss: 0.0912\n",
      "Train Step: 6 (64.00%)  \tLoss: 0.0678\n",
      "Train Step: 6 (85.33%)  \tLoss: 0.0150\n",
      "Test set: Average loss: 0.0797, Accuracy: 9767/10000 (97.67%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 7 (00.00%)  \tLoss: 0.0510\n",
      "Train Step: 7 (21.33%)  \tLoss: 0.0306\n",
      "Train Step: 7 (42.67%)  \tLoss: 0.0495\n",
      "Train Step: 7 (64.00%)  \tLoss: 0.0219\n",
      "Train Step: 7 (85.33%)  \tLoss: 0.0104\n",
      "Test set: Average loss: 0.0896, Accuracy: 9742/10000 (97.42%)\n",
      "\n",
      "Train Step: 8 (00.00%)  \tLoss: 0.0198\n",
      "Train Step: 8 (21.33%)  \tLoss: 0.0558\n",
      "Train Step: 8 (42.67%)  \tLoss: 0.0046\n",
      "Train Step: 8 (64.00%)  \tLoss: 0.0162\n",
      "Train Step: 8 (85.33%)  \tLoss: 0.0485\n",
      "Test set: Average loss: 0.0845, Accuracy: 9755/10000 (97.55%)\n",
      "\n",
      "Train Step: 9 (00.00%)  \tLoss: 0.0835\n",
      "Train Step: 9 (21.33%)  \tLoss: 0.0571\n",
      "Train Step: 9 (42.67%)  \tLoss: 0.0283\n",
      "Train Step: 9 (64.00%)  \tLoss: 0.0115\n",
      "Train Step: 9 (85.33%)  \tLoss: 0.1205\n",
      "Test set: Average loss: 0.0839, Accuracy: 9753/10000 (97.53%)\n",
      "\n",
      "Train Step: 10 (00.00%)  \tLoss: 0.0037\n",
      "Train Step: 10 (21.33%)  \tLoss: 0.0020\n",
      "Train Step: 10 (42.67%)  \tLoss: 0.0021\n",
      "Train Step: 10 (64.00%)  \tLoss: 0.0122\n",
      "Train Step: 10 (85.33%)  \tLoss: 0.0379\n",
      "Test set: Average loss: 0.0939, Accuracy: 9760/10000 (97.60%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 코드 2-28\n",
    "\n",
    "main(model=model, \n",
    "     train_loader=train_loader, \n",
    "     test_loader=test_loader, \n",
    "     loss_func=loss_function, \n",
    "     optimizer=optimizer, \n",
    "     n_step=STEP,\n",
    "     device=DEVICE,\n",
    "     save_path=\"mnist_model.pt\", \n",
    "     print_step=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved ./figs\\abc.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 만약에 해당 프로그램이 계속 실행안되고 재시작을 한다면 ssh 접속시\n",
    "# $ ssh -Y [host 이름]\n",
    "# 으로 실행해주시면 됩니다.\n",
    "img = drawing_custom_number(preprocess=True, return_img=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted number is 5.\n"
     ]
    }
   ],
   "source": [
    "# 코드 2-29\n",
    "\n",
    "# 내가 그린 이미지 테스트\n",
    "# 이미지를 (1, 28, 28) 크기의 텐서로 바꿔준다\n",
    "test_input = torch.Tensor(np.array(img)).unsqueeze(0).to(DEVICE)\n",
    "pred = model(test_input)\n",
    "print(\"Predicted number is {}.\".format(pred.softmax(1).argmax().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
